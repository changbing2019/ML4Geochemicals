{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd4b688",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\Anaconda3\\envs\\tf\\lib\\site-packages\\xgboost\\compat.py:36: FutureWarning: pandas.Int64Index is deprecated and will be removed from pandas in a future version. Use pandas.Index with the appropriate dtype instead.\n",
      "  from pandas import MultiIndex, Int64Index\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os, glob\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedKFold, cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "## The following are the ML models which can be used for trasinning\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "import timeit\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166ccab7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbca8f5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c59e722a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc20df9e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9d922587",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d4093",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52f6267a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataFolder = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "611f13d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "group1_low =1.634\n",
    "group2_low =0.673\n",
    "group2_upper =1.634\n",
    "group3_upper =0.673"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e90cd906",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## read the test file\n",
    "data =pd.read_csv(os.path.join(dataFolder,'10_PC_02_LHS_5000_54854_01_s1_G.csv'))\n",
    "data.columns =[col.strip() for col in data.columns]\n",
    "data['ratio'] = data['b(CaO)']/data['b(SiO2)']\n",
    "group1 = data[data['ratio']>=group1_low]  # with Portlandite, no Amor-S1\n",
    "group2 = data[(data['ratio']<=group2_upper) & (data['ratio']>=group2_low)]  # no Portlandite, no Amor-S1\n",
    "group3 = data[data['ratio']<=group3_upper]     # no Portlandite, with Amor-S1\n",
    "groups = [group1,group2,group3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4686c8f7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\projects\\\\MLChemicalR\\\\No_optimization\\\\case5HAll\\\\ModelTrainSummary.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[1;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m## read trained Model info:\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m modelInfo \u001b[38;5;241m=\u001b[39m\u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataFolder\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mModelTrainSummary.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m modelInfo \u001b[38;5;241m=\u001b[39m modelInfo\u001b[38;5;241m.\u001b[39miloc[:,\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m4\u001b[39m]\n\u001b[0;32m      4\u001b[0m modelInfo\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\util\\_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[0;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[0;32m    310\u001b[0m     )\n\u001b[1;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    666\u001b[0m     dialect,\n\u001b[0;32m    667\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    677\u001b[0m )\n\u001b[0;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\parsers\\readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1214\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1215\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[0;32m   1216\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[0;32m   1217\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[1;32m-> 1218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[0;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1228\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1229\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mE:\\Anaconda3\\envs\\tf\\lib\\site-packages\\pandas\\io\\common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[0;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\projects\\\\MLChemicalR\\\\No_optimization\\\\case5HAll\\\\ModelTrainSummary.csv'"
     ]
    }
   ],
   "source": [
    "## read trained Model info:\n",
    "modelInfo =pd.read_csv(os.path.join(dataFolder,'ModelTrainSummary.csv'))\n",
    "modelInfo = modelInfo.iloc[:,1:4]\n",
    "modelInfo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e0af0d0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelTypeLst = modelInfo['modelType'].unique()\n",
    "MLModels =[ml for ml in modelTypeLst if 'Model' in ml]\n",
    "nonMLModels = [ml for ml in modelTypeLst if 'Model' not in ml]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a340809e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb35307",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## load the mdoels\n",
    "dataCols = data.columns.to_list()\n",
    "modelsLst = []\n",
    "for irow,row in modelInfo.iterrows():\n",
    "    group = row['group']\n",
    "    var =row['var']\n",
    "    modelType = row['modelType']\n",
    "    icol =dataCols.index(var)\n",
    "    if '/' in var:\n",
    "        fileCol = var.replace(\"/\",'')\n",
    "    else:\n",
    "        fileCol = var            \n",
    "\n",
    "    modelFolder = os.path.join(dataFolder,'SavedModel',group)\n",
    "    if modelType=='CONST':\n",
    "        ext = '.csv'\n",
    "        fileName = os.path.join(modelFolder,modelType + '_'+str(icol)+'_'+fileCol+ext)\n",
    "        tempModel =pd.read_csv(fileName)\n",
    "    else:\n",
    "        ext ='.sav'\n",
    "        fileName = os.path.join(modelFolder,modelType + '_'+str(icol)+'_'+fileCol+ext)\n",
    "        tempModel = pickle.load(open(fileName, 'rb'))\n",
    "    \n",
    "    modelsLst.append(tempModel)\n",
    "\n",
    "modelInfo['modelObj'] = modelsLst   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826aee83",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96820fef",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "finalDF = pd.DataFrame()\n",
    "for ML in MLModels:\n",
    "    modelProcessing =[]\n",
    "    modelProcessing = nonMLModels.copy()\n",
    "    modelProcessing.append(ML)\n",
    "    tempModelInfo = modelInfo[modelInfo['modelType'].isin(modelProcessing)]\n",
    "    for col in group1.columns[4:-1]:  # exclude 'ratio' \n",
    "        colModelInfo = tempModelInfo[tempModelInfo['var'] == col]  \n",
    "        \n",
    "        for i, group in enumerate(groups):\n",
    "        \n",
    "            dataX = group.iloc[:,1:4]    \n",
    "            dataY = group[col].values\n",
    "            groupModelInfo = colModelInfo[colModelInfo['group'] =='group'+str(i+1)]\n",
    "            modelType = groupModelInfo['modelType'].values[0]\n",
    "            model = groupModelInfo['modelObj'].values[0]\n",
    "            if modelType=='CONST':\n",
    "                y_pred = list(model['const'].values)*len(dataY)\n",
    "                \n",
    "            elif modelType=='linear':\n",
    "                y_pred = model.predict(dataX.values)\n",
    "            \n",
    "            else:\n",
    "                scaler = StandardScaler().fit(dataX.values)\n",
    "                X_scaled = scaler.transform(dataX.values)  # This will be used for input of trainning dataset\n",
    "                y_pred  = model.predict(X_scaled)  \n",
    "    \n",
    "            tempDF = pd.DataFrame({'testDataY':dataY, 'predDataY':y_pred})\n",
    "            tempDF['modelType'] = [modelType]*len(tempDF)\n",
    "            tempDF['var'] = [col]*len(tempDF)\n",
    "            tempDF['group'] = ['group'+str(i+1)]*len(tempDF)\n",
    "            tempDF['modelSimulation'] = [ML+'_simulation']*len(tempDF)\n",
    "                \n",
    "            if len(finalDF)==0:   \n",
    "                finalDF = tempDF\n",
    "            else:\n",
    "                finalDF = pd.concat([finalDF,tempDF],axis=0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671276fc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "finalDF.to_csv('Comparison_predict_5KDataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9781dfe",
   "metadata": {},
   "source": [
    "# Visualization of the prediction of the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b3e74",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def drawPlots(trgVar,testDataY,predDataY,simulation):\n",
    "    \n",
    "    fig, ax =plt.subplots(figsize=(8,8))\n",
    "    \n",
    "    RMSE = mean_squared_error(testDataY,predDataY)\n",
    "    R2   = r2_score(testDataY,predDataY)\n",
    "    axMax = max(max(testDataY),max(predDataY))\n",
    "    axMin = min(min(testDataY),min(predDataY))\n",
    "    \n",
    "    ## Fitting the line           \n",
    "    x2= np.linspace(axMin,axMax,30);\n",
    "    y2 = x2\n",
    "    ax.plot(testDataY,predDataY,'bo',markerfacecolor = 'blue',markeredgecolor ='darkblue',markeredgewidth=0.5,label=trgVar)\n",
    "    \n",
    "    #ax.plot(df3['b(SiO2)'].values,df3['b(CaO)'].values,'bo',markerfacecolor = 'c',markeredgecolor ='b',markeredgewidth=0.5,label='no Amor-S1')\n",
    "    #ax.plot(group3['b(SiO2)'].values,group3['b(CaO)'].values,'g^',markerfacecolor = 'm',markeredgecolor ='m',markeredgewidth=1,label='group3')\n",
    "    ax.plot(x2,y2,'r-',lw=3,label ='1:1 ratio')\n",
    "    ax.legend (loc='best',ncol=5)           \n",
    "    ax.set_xlim(axMin,axMax)\n",
    "    ax.set_ylim(axMin,axMax)\n",
    "    #ax.text(0.05, 0.8, 'Above the line with Portlandite',fontsize = 20,color = 'k')\n",
    "    #ax.text(0.4, 0.50, 'Below the line no Portlandite',fontsize = 20,color = 'k')\n",
    "    ax.set_title(simulation+ ' ====> '+trgVar)\n",
    "    ax.set_xlabel('testDataY')\n",
    "    ax.set_ylabel('PredDataY')    \n",
    "        \n",
    "    return R2, RMSE    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fee0755",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07df49f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "modelSimulations = finalDF['modelSimulation'].unique()\n",
    "trgVars = finalDF['var'].unique()\n",
    "statMeasure = []\n",
    "for simulation in modelSimulations:\n",
    "    if 'MLP' in simulation or 'xgb' in simulation: # skip the xgb and MLP models\n",
    "        continue\n",
    "    tempDF = finalDF[finalDF['modelSimulation']==simulation]\n",
    "    for trgVar in trgVars:\n",
    "        df = tempDF[tempDF['var']==trgVar]  # no Portlandite\n",
    "        testDataY = df['testDataY'].values\n",
    "        predDataY = df['predDataY'].values\n",
    "        R2,RMSE = drawPlots(trgVar,testDataY,predDataY,simulation)\n",
    "        statMeasure.append([trgVar,R2,RMSE,simulation])\n",
    "    \n",
    "statMeasDF = pd.DataFrame(statMeasure,columns=['Var','R2','RMSE','modelSimulation'])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "403f2f2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "statMeasDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44cfebdf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "statMeasDF_pivot=statMeasDF.pivot(index='Var',values=['R2','RMSE'],columns='modelSimulation')\n",
    "statMeasDF.to_csv('statMeasure_trainDataset_noPivot.csv',index = False)\n",
    "\n",
    "statMeasDF_pivot.to_csv('statMeasure_trainDataset_Pivot.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e85a45e2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## alternative way to draw figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb09ff03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bad12a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def drawCombiningPlots(plotDataDF,trgVar):\n",
    "    \n",
    "    fig, ax =plt.subplots(figsize=(10,10))\n",
    "    \n",
    "    marker = ['o', 'v', '^', '<', '>', '8', 's', 'p', '*', 'h', 'H', 'D', 'd', 'P', 'X']\n",
    "    colors = ['tab:blue','tab:orange','tab:gray','tab:olive','tab:cyan','tab:green']\n",
    "    ## Fitting the line           \n",
    "    axisMin=1000\n",
    "    axisMax =-1000\n",
    "    for i, col in enumerate(plotDataDF.columns[1:]):\n",
    "        testDataY = plotDataDF.iloc[:,0].values\n",
    "        predDataY = plotDataDF[col].values\n",
    "        axMax = max(max(testDataY),max(predDataY))\n",
    "        axMin = min(min(testDataY),min(predDataY))\n",
    "        axisMin = min(axisMin,axMin)\n",
    "        axisMax = max(axisMax,axMax)\n",
    "        ax.scatter(testDataY,predDataY,marker =marker[i],edgecolor =colors[i],label=col.replace('_simulation',''))\n",
    "\n",
    "    x2= np.linspace(axisMin,axisMax,30);\n",
    "    y2 = x2\n",
    "    ax.plot(x2,y2,'r-',lw=3,label ='1:1 ratio')\n",
    "    ax.legend (loc='best',ncol=3)           \n",
    "    ax.set_xlim(axisMin,axisMax)\n",
    "    ax.set_ylim(axisMin,axisMax)\n",
    "    ax.set_title(trgVar)\n",
    "    ax.set_xlabel('testDataY')\n",
    "    ax.set_ylabel('PredDataY')    \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e491553e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "modelSimulations = finalDF['modelSimulation'].unique()\n",
    "trgVars = finalDF['var'].unique()\n",
    "for trgVar in trgVars:\n",
    "    tempdf = finalDF[finalDF['var']==trgVar]  # no Portlandite\n",
    "    dataplot = {}\n",
    "    plotDataDF = pd.DataFrame()\n",
    "    for simulation in modelSimulations:\n",
    "        # skip the xgb and MLP models\n",
    "        # the two models are very bad, need to be fine tune\n",
    "        if 'MLP' in simulation or 'xgb' in simulation: \n",
    "            continue\n",
    "\n",
    "        df = tempdf[tempdf['modelSimulation']==simulation]\n",
    "        if len(plotDataDF)==0:\n",
    "            plotDataDF=df[['testDataY','predDataY']]\n",
    "        else:    \n",
    "            plotDataDF = pd.concat([plotDataDF,df[['predDataY']]],axis=1)\n",
    "\n",
    "        plotDataDF.rename({'predDataY': simulation}, axis=1,inplace=True)\n",
    "                                    \n",
    "    drawCombiningPlots(plotDataDF,trgVar)    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cd174f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
