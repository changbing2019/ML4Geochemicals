{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ffe08f",
   "metadata": {},
   "source": [
    "This script is used for modeling pH of the particluar geochemical system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd4b688",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,mean_squared_error,r2_score\n",
    "\n",
    "## The following are the ML models which can be used for trasinning\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "import timeit\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166ccab7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbca8f5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c59e722a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d4093",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f6267a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dataFolder = os.getcwd()\n",
    "file = '10_PC_02_LHS_5000_54854_01_s1_G.csv' \n",
    "InsFile = os.path.join(dataFolder, file)\n",
    "data = pd.read_csv(InsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c56a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns =[col.strip() for col in data.columns]\n",
    "data['ratio'] = data['b(CaO)']/data['b(SiO2)']\n",
    "inputColNames =['b(CaO)','b(SiO2)','b(H2O)']\n",
    "inputColAqSiNames =['b(CaO)','b(SiO2)','b(H2O)','pH']\n",
    "\n",
    "scaler =  StandardScaler().fit(data[inputColNames].values)\n",
    "scalerSiaq = StandardScaler().fit(data[inputColAqSiNames].values)\n",
    "#Split the dataset intotrain dataset and test dataset\n",
    "trainData,testData = train_test_split(data,test_size=0.2, random_state=42,shuffle =True)\n",
    "#Split the train dataset into 3 groups\n",
    "# Group divider\n",
    "group1_low =1.634\n",
    "group2_low =0.673\n",
    "group2_upper =1.634\n",
    "group3_upper =0.673\n",
    "train_group1 = trainData[trainData['ratio']>group1_low]  # with Portlandite, no Amor-S1\n",
    "train_group1=train_group1.reset_index(drop=True)\n",
    "train_group2 = trainData[(trainData['ratio']<=group2_upper) & (trainData['ratio']>=group2_low)]  # no Portlandite, no Amor-S1\n",
    "train_group2=train_group2.reset_index(drop=True)\n",
    "train_group3 = trainData[trainData['ratio']<group3_upper]     # no Portlandite, with Amor-S1\n",
    "train_group3=train_group3.reset_index(drop=True)\n",
    "\n",
    "train_GroupData = [train_group1,train_group2,train_group3]\n",
    "\n",
    "test_group1 = testData[testData['ratio']>group1_low]  # with Portlandite, no Amor-S1\n",
    "test_group1 = test_group1.reset_index(drop=True)\n",
    "\n",
    "test_group2 = testData[(testData['ratio']<=group2_upper) & (testData['ratio']>=group2_low)]  # no Portlandite, no Amor-S1\n",
    "test_group2 = test_group2.reset_index(drop=True)\n",
    "test_group3 = testData[testData['ratio']<group3_upper]     # no Portlandite, with Amor-S1\n",
    "test_group3 = test_group3.reset_index(drop=True)\n",
    "test_GroupData = [test_group1,test_group2,test_group3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "611f13d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e90cd906",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## The target variables you want to simulate\n",
    "# pH should be estiamted first because NSiO2 dpends on pH estimates for Group 2\n",
    "targetColumnNames = ['pH','nSi(aq)'] #,'nCa(aq)','nCa(s)','nSi(aq)','nSi(s_reac)','nPortlandite']\n",
    "## Save training infomation to a file\n",
    "modeSumarryFileName = 'ModelTrainSummary.csv'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1ae380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPyModel(xtrain,ytrain,OutFP):\n",
    "    \n",
    "    GPy_Model = GaussianProcessRegressor(kernel=Matern(length_scale=[1,1,1], nu=2.5), alpha= 1.0e-7,n_restarts_optimizer=10, normalize_y=True)\n",
    "    #GPy_random = RandomizedSearchCV(estimator = GPy_Model, param_distributions = random_GPyModel, scoring = 'r2',n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    GPy_Model.fit(xtrain, ytrain)        \n",
    "    pickle.dump(GPy_Model, open(OutFP, 'wb'))             \n",
    "    # Cross Validation\n",
    "    scores = outputModelTrainningScore(GPy_Model,xtrain,ytrain,nCV=10)     \n",
    "    return GPy_Model,scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e260621",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPyModelAqSpecies(xtrain,ytrain,OutFP):\n",
    "    \n",
    "    GPy_Model = GaussianProcessRegressor(kernel=Matern(length_scale=[1,1,1,1], nu=2.5),alpha = 1.0e-7, n_restarts_optimizer=10, normalize_y=True)\n",
    "    #GPy_random = RandomizedSearchCV(estimator = GPy_Model, param_distributions = random_GPyModel, scoring = 'r2',n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    GPy_Model.fit(xtrain, ytrain)        \n",
    "    pickle.dump(GPy_Model, open(OutFP, 'wb'))             \n",
    "    # Cross Validation\n",
    "    scores = outputModelTrainningScore(GPy_Model,xtrain,ytrain,nCV=10)     \n",
    "\n",
    "    return GPy_Model,scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2a49f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputModelTrainningScore(model,X,y,nCV=10):\n",
    "    R2_score = cross_val_score(model, X, y,scoring='r2', cv=nCV)\n",
    "    RMSE_score = cross_val_score(model, X, y,scoring='neg_root_mean_squared_error', cv=10)\n",
    "    MAE_score = cross_val_score(model, X, y,scoring='neg_mean_absolute_error', cv=10) \n",
    "    R2_score_mean = R2_score.mean()\n",
    "    RMSE_score_mean = RMSE_score.mean()\n",
    "    MAE_score_mean = MAE_score.mean()\n",
    "    return [R2_score_mean,RMSE_score_mean, MAE_score_mean] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2020f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b75d59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training With ===> group1 Target==> pH\n",
      "Training With ===> group1 Target==> nSi(aq)\n"
     ]
    }
   ],
   "source": [
    "groupLst=[]\n",
    "varLst = []\n",
    "modelTypeLst = []\n",
    "trainScore = []\n",
    "dfTestResults = pd.DataFrame()\n",
    "for i, (trainGroupData, testGroupData) in enumerate(zip(train_GroupData,test_GroupData)):\n",
    "    group = 'group' +str(i+1)\n",
    "    outFolder = os.path.join(dataFolder,'SavedModel',group)\n",
    "    if not os.path.exists(outFolder):\n",
    "         os.makedirs(outFolder)\n",
    "    \n",
    "    for col in targetColumnNames: \n",
    "        # CHeck the col is in the dataFrame\n",
    "        if col not in trainGroupData.columns:\n",
    "            sys.exit('The target column is not defined in the dataset, please check!')                \n",
    "        \n",
    "        print('Training With ===>', group,'Target==>',col)\n",
    "        \n",
    "        trainDataX=trainGroupData[inputColNames];\n",
    "        trainDataY = trainGroupData[col]\n",
    "        ## Check the max and min value of Y\n",
    "        ## IF change of Y is less than 1%,\n",
    "        ## then the target will be considered as constant, and \n",
    "        ## this value will be applied to the group\n",
    "        \n",
    "        X = trainDataX.values\n",
    "        Y = trainDataY.values\n",
    "        if '/' in col:\n",
    "            fileCol = col.replace(\"/\",'')\n",
    "        else:\n",
    "            fileCol = col            \n",
    "        if Y.max()+Y.min() != 0:\n",
    "            percnt = (Y.max()-Y.min())/(Y.max()+Y.min())*200.0\n",
    "        else:\n",
    "            percnt =0.0\n",
    "        if percnt <1.0:\n",
    "            fileName = os.path.join(outFolder,'const_'+fileCol+'.csv')\n",
    "            constVal = (Y.max()+Y.min())*0.5\n",
    "            tempdf = pd.DataFrame({'var':[col],'const':[constVal]})\n",
    "            tempdf.to_csv(fileName,index=False)\n",
    "            modelTypeLst.append('CONST')\n",
    "            trainScore.append([0,0,0])\n",
    "            groupLst.append(group)\n",
    "            varLst.append(col)\n",
    "            groupPredDF = pd.DataFrame({'testDataY':testGroupData[col].values,\n",
    "                                        'predDataY':[constVal]*len(testGroupData),\n",
    "                                        'predCI_low':[constVal]*len(testGroupData),\n",
    "                                        'predCI_upp':[constVal]*len(testGroupData),\n",
    "                                        'group':[group]*len(testGroupData),\n",
    "                                        'var':[col]*len(testGroupData),\n",
    "                                        'modelType':['CONST']*len(testGroupData)}) \n",
    "            if len(dfTestResults)==0:\n",
    "                dfTestResults = groupPredDF\n",
    "            else:\n",
    "                dfTestResults = pd.concat([dfTestResults,groupPredDF],axis=0)\n",
    "                \n",
    "            continue\n",
    "            \n",
    "        # Check the correlation of each of dataX to DataY \n",
    "        corrLst = []\n",
    "        for colX in trainDataX.columns:\n",
    "            corr = trainDataX[colX].corr(trainDataY)\n",
    "            corrLst.append(abs(corr))\n",
    "        \n",
    "        if max(corrLst)>=0.99:   # we use a linear model to simulate\n",
    "            #give the X and Y for fiting a linear model                   \n",
    "            regLinear = LinearRegression().fit(X, Y) \n",
    "            # conduct cross validation\n",
    "            scores = outputModelTrainningScore(regLinear,X,Y,nCV=10)     \n",
    "            trainScore.append(scores)\n",
    "            groupLst.append(group)\n",
    "            varLst.append(col)\n",
    "            modelTypeLst.append('linear')  \n",
    "            fileName = os.path.join(outFolder,'linear_'+fileCol+'.sav')\n",
    "            pickle.dump(regLinear, open(fileName, 'wb'))    \n",
    "            testX = testGroupData[inputColNames].values\n",
    "            testY = testGroupData[col].values\n",
    "            predY = regLinear.predict(testX)\n",
    "            groupPredDF = pd.DataFrame({'testDataY':testY,\n",
    "                                        'predDataY':predY,\n",
    "                                        'predCI_low':predY,\n",
    "                                        'predCI_upp':predY,\n",
    "                                        'group':[group]*len(testGroupData),\n",
    "                                        'var':[col]*len(testGroupData),\n",
    "                                        'modelType':['Linear']*len(testGroupData)}) \n",
    "            \n",
    "            if len(dfTestResults)==0:\n",
    "                dfTestResults = groupPredDF\n",
    "            else:\n",
    "                dfTestResults = pd.concat([dfTestResults,groupPredDF],axis=0)\n",
    "            \n",
    "            continue\n",
    "            \n",
    "        if col == 'nSi(aq)' and group =='group2':  # need to add pH as another input to the model \n",
    "            trainDataX = trainGroupData[inputColAqSiNames ].reset_index(drop=True)\n",
    "            X = trainDataX.values\n",
    "            Y = trainDataY.values\n",
    "            X_scaled = scalerSiaq.transform(X)  \n",
    "            fileName = os.path.normpath( os.path.join( outFolder,'GPyModel_'+fileCol+'.sav' ) )             \n",
    "            GPy,scores = GPyModelAqSpecies(X_scaled,Y,fileName)\n",
    "            groupLst.append(group)\n",
    "            varLst.append(col)\n",
    "            modelTypeLst.append('GPyModel')  \n",
    "            trainScore.append(scores)\n",
    "            ## Get the pH value from the dfTestResults dataframe\n",
    "            dfTemp = dfTestResults[(dfTestResults['group']=='group2') & (dfTestResults['var']=='pH')]\n",
    "            testX = testGroupData[inputColNames].reset_index(drop=True)\n",
    "            testX['pH'] = dfTemp['predDataY']\n",
    "            testX_scaled = scalerSiaq.transform(testX.values)  \n",
    "            testY = testGroupData[col].values\n",
    "            predY,predYStd = GPy.predict(testX_scaled, return_std=True)\n",
    "            CI_low = predY - predYStd\n",
    "            CI_upp = predY + predYStd\n",
    "            groupPredDF = pd.DataFrame({'testDataY':testY,\n",
    "                                        'predDataY':predY,\n",
    "                                        'predCI_low':CI_low,\n",
    "                                        'predCI_upp':CI_upp,\n",
    "                                        'group':[group]*len(testGroupData),\n",
    "                                        'var':[col]*len(testGroupData),\n",
    "                                        'modelType':['GPY']*len(testGroupData)}) \n",
    "            \n",
    "            if len(dfTestResults)==0:\n",
    "                dfTestResults = groupPredDF\n",
    "            else:\n",
    "                dfTestResults = pd.concat([dfTestResults,groupPredDF],axis=0)\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        if col =='pH' and group =='group2':\n",
    "            ## Use all the train dataset for this case      \n",
    "            dataX=trainData[inputColNames].reset_index(drop=True)  \n",
    "            dataY=trainData[col].reset_index(drop=True)\n",
    "            X = dataX.values\n",
    "            Y = dataY.values\n",
    "            print(X.shape,Y.shape)\n",
    "            \n",
    "        fileName = os.path.normpath( os.path.join( outFolder,'GPyModel_'+fileCol+'.sav' ) )             \n",
    "        X_scaled = scaler.transform(X)  \n",
    "        GPy,scores = GPyModel(X_scaled,Y,fileName)\n",
    "        groupLst.append(group)\n",
    "        varLst.append(col)\n",
    "        modelTypeLst.append('GPyModel')  \n",
    "        trainScore.append(scores)\n",
    "        \n",
    "        testX = testGroupData[inputColNames].values\n",
    "        testX_scaled = scaler.transform(testX) \n",
    "        testY = testGroupData[col].values\n",
    "        predY,predYStd = GPy.predict(testX_scaled, return_std=True)\n",
    "        CI_low = predY - predYStd\n",
    "        CI_upp = predY + predYStd\n",
    "        \n",
    "        groupPredDF = pd.DataFrame({'testDataY':testY,\n",
    "                                    'predDataY':predY,\n",
    "                                    'predCI_low':CI_low,\n",
    "                                    'predCI_upp':CI_upp,\n",
    "                                    'group':[group]*len(testGroupData),\n",
    "                                    'var':[col]*len(testGroupData),\n",
    "                                    'modelType':['GPY']*len(testGroupData)}) \n",
    "        if len(dfTestResults)==0:\n",
    "            dfTestResults = groupPredDF\n",
    "        else:\n",
    "            dfTestResults = pd.concat([dfTestResults,groupPredDF],axis=0)\n",
    "        \n",
    "        \n",
    "ModelTrainSummary = pd.DataFrame({'group':groupLst,'var':varLst,'modelType':modelTypeLst})\n",
    "ModelTrainMeasures = pd.DataFrame(trainScore,columns=['R2_mean','RMSE_mean','MAE_mean'])\n",
    "ModelTrainSummary = pd.concat([ModelTrainSummary,ModelTrainMeasures],axis=1)\n",
    "ModelTrainSummary.to_csv(modeSumarryFileName, index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6eb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ab566",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTestResults.to_csv('SimulatedReusltsWithTestDataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a465c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPlotsV2(trgVar,df,simulation,scale):\n",
    "    \n",
    "    fig, ax =plt.subplots(figsize=(8,8))\n",
    "    df = df.sort_values(by=['testDataY'])\n",
    "    axMax = max(df['testDataY'].max(),df['predDataY'].max())\n",
    "    axMax =axMax +axMax*0.05\n",
    "    axMin = min(df['testDataY'].min(),df['predDataY'].min())\n",
    "    axMin = axMin - axMin*0.05\n",
    "    x2= np.linspace(axMin,axMax,30);\n",
    "    y2 = x2\n",
    "    df1 = df[df['group']=='group1']\n",
    "    df1 =df1.reset_index(drop=True)\n",
    "    ax.fill_between(df1['testDataY'], df1['predCI_low'],  df1['predCI_upp'], alpha=0.6)\n",
    "    ax.plot(df1['testDataY'],df1['predDataY'],'bo',markersize =12,label ='Group 1')\n",
    "    df2 = df[df['group']=='group2']\n",
    "    df2 =df2.reset_index(drop=True)\n",
    "    ax.fill_between(df2['testDataY'], df2['predCI_low'],  df2['predCI_upp'], alpha=0.6)\n",
    "    ax.plot(df2['testDataY'],df2['predDataY'],'go',markersize =6,label ='Group 2')\n",
    "    df3 = df[df['group']=='group3']\n",
    "    df3 =df3.reset_index(drop=True)\n",
    "    ax.fill_between(df3['testDataY'], df3['predCI_low'],  df3['predCI_upp'], alpha=0.6)\n",
    "    ax.plot(df3['testDataY'],df3['predDataY'],'yo',markersize =12,label ='Group 3')\n",
    "\n",
    "    ax.plot(x2,y2,'r-',lw=3,label ='1:1 ratio')\n",
    "    ax.legend (loc='best',ncol=5)           \n",
    "    ax.set_xlim(axMin,axMax)\n",
    "    ax.set_ylim(axMin,axMax)\n",
    "    ax.legend (loc='best',ncol=2)\n",
    "    if scale=='log':\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "    ax.set_title(simulation+ ' ====> '+trgVar)\n",
    "    ax.set_xlabel('testDataY')\n",
    "    ax.set_ylabel('PredDataY')    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPlot = dfTestResults[dfTestResults['var']=='pH']\n",
    "drawPlotsV2('pH',dfPlot,'GPy',scale='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6069c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPlot = dfTestResults[dfTestResults['var']=='nSi(aq)']\n",
    "drawPlotsV2('nSi(aq)',dfPlot,'GPy',scale='log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc8c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
